{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importation des Librairies + Datasets"
      ],
      "metadata": {
        "id": "-FCuOfcE54aj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8j-0k2JIPkde"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configuration pour afficher tous les graphiques dans le notebook\n",
        "%matplotlib inline\n",
        "sns.set_theme(style=\"whitegrid\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement des 4 piliers du projet\n",
        "objects = pd.read_csv('objects.csv', encoding='ISO-8859-1')\n",
        "funding_rounds = pd.read_csv('funding_rounds.csv', encoding='ISO-8859-1')\n",
        "investments = pd.read_csv('investments.csv', encoding='ISO-8859-1')\n",
        "acquisitions = pd.read_csv('acquisitions.csv', encoding='ISO-8859-1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "I1SDT4mwob3t",
        "outputId": "9a6802c9-3b30-4738-9e96-d28dfe81405e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: EOF inside string starting at row 16826",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-895962019.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Chargement des 4 piliers du projet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mobjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'objects.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ISO-8859-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfunding_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'funding_rounds.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ISO-8859-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minvestments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'investments.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ISO-8859-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0macquisitions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'acquisitions.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ISO-8859-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: EOF inside string starting at row 16826"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyse des fichiers"
      ],
      "metadata": {
        "id": "OmOxLZQA4DfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionnaire des DataFrames pour automatiser l'analyse\n",
        "datasets = {\n",
        "    \"Objects\": objects,\n",
        "    \"Funding Rounds\": funding_rounds,\n",
        "    \"Investments\": investments,\n",
        "    \"Acquisitions\": acquisitions\n",
        "}\n",
        "\n",
        "for name, df in datasets.items():\n",
        "    print(f\"\\n{'='*20} {name} {'='*20}\")\n",
        "    # Analyse de la structure [cite: 350]\n",
        "    print(f\"Dimensions : {df.shape}\")\n",
        "    print(\"\\n--- Infos structurelles ---\")\n",
        "    df.info()\n",
        "    # Détection des valeurs manquantes [cite: 352]\n",
        "    print(\"\\n--- Valeurs manquantes ---\")\n",
        "    print(df.isnull().sum())\n",
        "    # Visualisation d'un échantillon [cite: 347]\n",
        "    print(\"\\n--- Échantillon (10 lignes) ---\")\n",
        "    display(df.head(10))"
      ],
      "metadata": {
        "id": "3uGdduF2s0u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Analyse Objects.csv\n",
        "\n",
        "- Plus de 73% de manquants pour category_code et 78% pour founded_at\n",
        "\n",
        "- De nombreuses colonnes comme parent_id, logo_url ou domain n'ont aucune valeur prédictive pour le succès d'une startup\n",
        "\n",
        "## 2. Analyse funding_rounds.csv\n",
        "\n",
        "- Contrairement au fichier Objects, la colonne cruciale raised_amount_usd ne présente aucune valeur manquante (52 928 non-null). C'est une excellente nouvelle pour la précision de votre futur modèle supervisé.\n",
        "\n",
        "- Les colonnes de valorisation (pre_money_valuation et post_money_currency_code) sont vides à près de 50%. Elles seront donc écartées pour éviter de réduire drastiquement la taille du dataset final.\n",
        "\n",
        "- La date de levée (funded_at) est quasi complète (seulement 248 manquants sur 53k lignes), ce qui permettra de calculer la vélocité de financement.\n",
        "\n",
        "## 3. Analyse investments.csv\n",
        "\n",
        "- Ce fichier est techniquement \"parfait\" avec 0 valeur manquante sur les 80 902 lignes.\n",
        "\n",
        "- Il contient les clés de liaison fondamentales : funded_object_id (la startup) et investor_object_id (l'investisseur)\n",
        "\n",
        "- Il s'agit d'une table de faits qui répertorie chaque participation d'un investisseur à un round de financement.\n",
        "\n",
        "## 4. Analyse acquisitions.csv\n",
        "\n",
        "- Ce fichier identifie les cibles (acquired_object_id) et les acheteurs (acquiring_object_id).\n",
        "\n",
        "- La structure est relativement saine pour les colonnes d'identification. Cependant, les colonnes financières (price_amount) et contractuelles (term_code) sont très lacunaires ou comportent des valeurs à zéro.\n",
        "\n",
        "- Le term_code est manquant à 80 % (7 656 vides). Comme pour les fichiers précédents, nous allons écarter les colonnes \"bruit\" (URLs, descriptions) pour optimiser la mémoire.\n"
      ],
      "metadata": {
        "id": "rJDOwPJd4LsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase de Nettoyage"
      ],
      "metadata": {
        "id": "aVzna1B26I1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Nettoyage objects.csv"
      ],
      "metadata": {
        "id": "Rj-zbpVY7T8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Filtrage par entité (Action métier obligatoire)\n",
        "# On ne garde que les entreprises (Company) pour cibler la problématique\n",
        "df_objects_clean = objects[objects['entity_type'] == 'Company'].copy()\n",
        "\n",
        "# 2. Sélection des colonnes stratégiques (Réduction de dimensionnalité)\n",
        "# On supprime les colonnes inutiles ou trop vides pour optimiser la mémoire\n",
        "cols_to_keep = [\n",
        "    'id', 'name', 'category_code', 'status', 'founded_at',\n",
        "    'country_code', 'funding_total_usd', 'funding_rounds', 'relationships'\n",
        "]\n",
        "df_objects_clean = df_objects_clean[cols_to_keep]\n",
        "\n",
        "# 3. Traitement des valeurs manquantes\n",
        "# On supprime les lignes sans secteur, pays ou date (trop critiques pour être imputées)\n",
        "df_objects_clean.dropna(subset=['category_code', 'founded_at', 'country_code'], inplace=True)\n",
        "\n",
        "# 4. Standardisation des types\n",
        "# Conversion de la date de fondation en objet datetime\n",
        "df_objects_clean['founded_at'] = pd.to_datetime(df_objects_clean['founded_at'], errors='coerce')\n",
        "\n",
        "# 5. Création de la variable Target\n",
        "# Transformation du statut en binaire : 1 si succès (acquired/ipo), 0 sinon\n",
        "df_objects_clean['is_success'] = df_objects_clean['status'].apply(lambda x: 1 if x in ['acquired', 'ipo'] else 0)\n",
        "\n",
        "print(f\"Volume après nettoyage : {df_objects_clean.shape}\")"
      ],
      "metadata": {
        "id": "eIk8jmTk4JcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Un modèle ne peut être meilleur que la donnée fournie. En supprimant les lignes incomplètes sur les secteurs et les dates, on assure des résultats généralisables\n",
        "\n",
        "- Les algorithmes de ML ne traitent pas les dates brutes ; la conversion est un prérequis obligatoire pour l'ingénierie de variables futures.\n",
        "\n",
        "- Cette approche réduit le volume global mais augmente la densité d'information, ce qui est le plus important pour notre scoring"
      ],
      "metadata": {
        "id": "FE9kEvK9-Gd0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Nettoyage funding_rounds.csv"
      ],
      "metadata": {
        "id": "IH4mkQ2a7eDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Sélection des colonnes utiles (Réduction de la dette technique)\n",
        "cols_finance = ['object_id', 'funding_round_type', 'raised_amount_usd', 'funded_at']\n",
        "df_rounds_clean = funding_rounds[cols_finance].copy()\n",
        "\n",
        "# Suppression des rares lignes sans date\n",
        "df_rounds_clean.dropna(subset=['funded_at'], inplace=True)\n",
        "\n",
        "# Conversion au format Datetime (\n",
        "df_rounds_clean['funded_at'] = pd.to_datetime(df_rounds_clean['funded_at'], errors='coerce')\n",
        "\n",
        "# Aperçu statistique des montants (Détection d'outliers)\n",
        "print(\"Statistiques des levées (USD) :\")\n",
        "print(df_rounds_clean['raised_amount_usd'].describe())\n",
        "\n",
        "print(f\"\\nVolume final de df_rounds_clean : {df_rounds_clean.shape}\")"
      ],
      "metadata": {
        "id": "OysTJ1FD7cYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- On ne conserve que la \"moelle épinière\" financière : l'ID de la startup, le type de round, le montant en USD et la date.\n",
        "\n",
        "- Conversion de funded_at en format datetime pour permettre les calculs chronologiques.\n",
        "\n",
        "- S'assurer que les montants sont bien traités comme des numériques continus pour le futur scaling."
      ],
      "metadata": {
        "id": "uXJ7OTLR-E5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Nettoyage investments.csv"
      ],
      "metadata": {
        "id": "4rn44S5O83Gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Sélection des colonnes relationnelles\n",
        "df_investments_clean = investments[['funding_round_id', 'funded_object_id', 'investor_object_id']].copy()\n",
        "\n",
        "# Détection et suppression des doublons\n",
        "duplicate_count = df_investments_clean.duplicated().sum()\n",
        "print(f\"Nombre de doublons détectés : {duplicate_count}\")\n",
        "df_investments_clean.drop_duplicates(inplace=True)\n",
        "\n",
        "# Vérification de la structure\n",
        "print(f\"Volume final de df_investments_clean : {df_investments_clean.shape}\")\n",
        "display(df_investments_clean.head(10))"
      ],
      "metadata": {
        "id": "qP771L6X8D85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Suppression des doublons pour éviter de surestimer l'influence d'un investisseur dans votre futur calcul de prestige\n",
        "\n",
        "- Suppression des colonnes temporelles système (created_at, updated_at) qui ne servent pas à la modélisation métier.\n",
        "\n",
        "-On ne garde que le triplet funding_round_id, funded_object_id et investor_object_id pour la préparation de graphs"
      ],
      "metadata": {
        "id": "-rfxKmVk-PIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Nettoyage acquisition.csv"
      ],
      "metadata": {
        "id": "J0fgYsU69ebg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sélection des colonnes essentielles pour le marquage du succès\n",
        "df_acq_clean = acquisitions[['acquired_object_id', 'acquired_at']].copy()\n",
        "\n",
        "# Suppression de la seule ligne manquante sur l'ID de la cible\n",
        "df_acq_clean.dropna(subset=['acquired_object_id'], inplace=True)\n",
        "\n",
        "# Conversion au format Datetime\n",
        "df_acq_clean['acquired_at'] = pd.to_datetime(df_acq_clean['acquired_at'], errors='coerce')\n",
        "\n",
        "# Suppression des doublons (Une startup ne peut être acquise qu'une fois)\n",
        "df_acq_clean.drop_duplicates(subset=['acquired_object_id'], inplace=True)\n",
        "\n",
        "print(f\"Volume final de df_acq_clean : {df_acq_clean.shape}\")"
      ],
      "metadata": {
        "id": "P-dGeVgM9oyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Nous allons utiliser ce fichier uniquement pour créer un dictionnaire de succès. Si une startup apparaît ici, elle est marquée comme is_success = 1 dans notre dataset final.\n",
        "\n",
        "- Suppression des colonnes inutiles (source_url, source_description, created_at).\n",
        "\n",
        "- Conversion de acquired_at en datetime."
      ],
      "metadata": {
        "id": "b9TKQcjK-NN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Données prêtes:\n",
        "\n",
        "- df_objects_clean : L'identité des startups.\n",
        "\n",
        "- df_rounds_clean : L'historique des financements.\n",
        "\n",
        "- df_investments_clean : Le réseau des investisseurs.\n",
        "\n",
        "- df_acq_clean : Le registre des succès.\n",
        "\n",
        "\n",
        "Nous allons maintenant passer à à la fusion de nos informations nettoyéesdans un DataFrame nommé df_final. Celui ci nous servira à l'analyse Eploratoire (EDA) et à l'entrainement de nos modèles."
      ],
      "metadata": {
        "id": "G_zHE_JM_foG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Distribution des Top 10 Secteurs (df_objects_clean)\n",
        "plt.figure(figsize=(12, 6))\n",
        "top_categories = df_objects_clean['category_code'].value_counts().head(10)\n",
        "sns.barplot(x=top_categories.values, y=top_categories.index, palette='viridis')\n",
        "plt.title('Top 10 des Secteurs d\\'Activité (Après Nettoyage)')\n",
        "plt.xlabel('Nombre d\\'entreprises')\n",
        "plt.ylabel('Secteur')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BM-WafUxA-Ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remarque sur le graphique :\n",
        "\n",
        "- Le graphique montre une domination nette des secteurs liés au Software, au Web et à l'Entreprise.\n",
        "\n",
        "- Malgré un gros nettoyage  ayant réduit le volume à environ 64 000 entreprises, la distribution reste représentative de l'économie numérique.\n",
        "\n",
        "- Cette forte concentration suggère que le secteur d'activité sera une variable catégorielle déterminante (Feature) pour nos modèles de Machine Learning.\n"
      ],
      "metadata": {
        "id": "M1EbLMXDGzMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Visualisation des Outliers Financiers (Fichier Funding Rounds)\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(x=df_rounds_clean['raised_amount_usd'])\n",
        "plt.xscale('log') # Échelle log car l'écart entre 0 et 3.8 milliards est trop grand\n",
        "plt.title('Distribution des Montants Levés (Échelle Logarithmique)')\n",
        "plt.xlabel('Montant en USD (Log)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0rhzV05Z_kdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remarque sur le graphique :\n",
        "\n",
        "- L'utilisation d'une échelle logarithmique est indispensable pour visualiser la donnée tant les écarts sont massifs (de quelques milliers à 3,8 milliards USD).\n",
        "\n",
        "- Le boxplot révèle une multitude d'outliers (valeurs aberrantes) situés bien au-delà de la moustache supérieure. Cela confirme l'asymétrie (skewness) de la donnée financière.\n",
        "\n",
        "- Ce graphique justifie mathématiquement notre choix d'utiliser la médiane ($\\approx 1,6 \\text{M USD}$) plutôt que la moyenne ($\\approx 7,9 \\text{M USD}$) pour l'imputation, car la moyenne est artificiellement tirée vers le haut par les \"méga-levées\"55."
      ],
      "metadata": {
        "id": "77vSFhY5HNog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Répartition des types de financement\n",
        "plt.figure(figsize=(10, 6))\n",
        "round_types = df_rounds_clean['funding_round_type'].value_counts()\n",
        "sns.countplot(data=df_rounds_clean, y='funding_round_type', order=round_types.index, palette='magma')\n",
        "plt.title('Répartition des Types de Levées de Fonds')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0Pe9uZLKGFzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remarque sur le graphique :  \n",
        "\n",
        "- Les rounds de type Seed et Series-A sont les plus fréquents, suivis par les investissements \"Angel\"\n",
        "\n",
        "- Le dataset capture majoritairement des startups en phase de démarrage. Pour notre modèle, la transition vers des Series-B ou C sera un signal fort de survie et de succès potentiel.\n",
        "\n",
        "- Cette distribution nous incite à traiter le funding_round_type comme une variable ordinale lors du préprocessing."
      ],
      "metadata": {
        "id": "8IP3tmvlHlRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fusion des données nettoyées :"
      ],
      "metadata": {
        "id": "9iwDynNRA_Ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Agrégation des levées de fonds par startup\n",
        "# On calcule le montant total levé et le nombre de rounds pour chaque entreprise\n",
        "df_rounds_agg = df_rounds_clean.groupby('object_id').agg({\n",
        "    'raised_amount_usd': 'sum',\n",
        "    'funding_round_type': 'count'\n",
        "}).rename(columns={\n",
        "    'raised_amount_usd': 'total_funding_usd',\n",
        "    'funding_round_type': 'funding_rounds_count'\n",
        "}).reset_index()\n",
        "\n",
        "# 2. Fusion de la table Objects avec les données financières\n",
        "# Utilisation d'un 'left join' pour garder toutes les boîtes nettoyées\n",
        "df_final = pd.merge(df_objects, df_rounds_agg, left_on='id', right_on='object_id', how='left')\n",
        "\n",
        "# 3. Marquage des succès via la table Acquisitions\n",
        "# On vérifie si l'ID de la startup est présent dans la liste des acquisitions\n",
        "df_final = pd.merge(df_final, df_acq_clean[['acquired_object_id', 'acquired_at']],\n",
        "                    left_on='id', right_on='acquired_object_id', how='left')\n",
        "\n",
        "# 4. Finalisation de la variable cible 'is_success'\n",
        "# Une startup a réussi si elle est déjà marquée 'acquired'/'ipo' OU si elle est dans df_acq\n",
        "df_final['is_success'] = df_final['is_success'].fillna(0)\n",
        "df_final.loc[df_final['acquired_at'].notnull(), 'is_success'] = 1\n",
        "\n",
        "# 5. Nettoyage final post-fusion\n",
        "df_final['total_funding_usd'] = df_final['total_funding_usd'].fillna(0)\n",
        "df_final['funding_rounds_count'] = df_final['funding_rounds_count'].fillna(0)\n",
        "\n",
        "# Suppression des colonnes techniques de jointure devenues inutiles\n",
        "df_final.drop(columns=['object_id', 'acquired_object_id', 'acquired_at'], inplace=True)\n",
        "\n",
        "print(f\"Volume du dataset consolidé : {df_final.shape}\")\n",
        "display(df_final.head())"
      ],
      "metadata": {
        "id": "NT4L-bkhJkoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rapport sur le Merge :\n",
        "\n",
        "- objects.csv est devenu Le Squelette : Il fournit la structure de base (ID, Nom, Secteur, Pays, Date de fondation). C'est la table \"maître\" qui porte l'identité de chaque startup.\n",
        "\n",
        "\n",
        "- funding_rounds.csv sert de carburant : Il a été \"compressé\" via une agrégation. Au lieu d'avoir plusieurs lignes par startup pour chaque levée, on a désormais deux indicateurs uniques par entreprise : total_funding_usd (somme de l'argent reçu) et funding_rounds_count (nombre de fois où elle a levé des fonds).\n",
        "\n",
        "\n",
        "\n",
        "- acquisitions.csv sert de dictionnaire de vérification. Si l'ID d'une startup était présent dans ce fichier, nous avons forcé sa variable is_success à 1, même si son statut initial dans objects n'était pas à jour.\n",
        "\n",
        "- Enfin investments.csv sera utilisé pour la partie Modèle non-supervisé pour calcluer l'influence des investisseur sans polluer la structure de la table de classification supervisée.\n",
        "\n",
        "Les données de financement ont été transformées par une opération de groupby, permettant de convertir un historique transactionnel en variables statistiques clés : le montant total levé et le nombre de rounds de financement.\n",
        "\n",
        "Étiquetage de la cible : La variable cible is_success a été binarisée (0 ou 1) en croisant le statut initial avec le registre des acquisitions, garantissant une vérité terrain fiable pour l'entraînement des futurs modèles.\n",
        "\n",
        "- Le dataset final comprend 64 099 observations et 12 variables prédictives.\n",
        "\n",
        "- Cohérence métier : L'analyse des premières lignes (échantillon) confirme la robustesse de la fusion : les startups à succès (ex: FriendFeed) sont correctement identifiées avec leurs indicateurs financiers et relationnels respectifs.\n",
        "\n",
        "- Prêt pour la modélisation : Cette table unique réunit désormais les dimensions temporelles, géographiques, sectorielles et financières nécessaires pour répondre à notre problématique de prédiction."
      ],
      "metadata": {
        "id": "X5cv04caKpHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modèle non-supervisé"
      ],
      "metadata": {
        "id": "oVi6IXwgY22A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrice de corrélation\n",
        "plt.figure(figsize=(10, 8))\n",
        "# On ne garde que les colonnes numériques\n",
        "sns.heatmap(df_final.select_dtypes(include=[np.number]).corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Matrice de Corrélation - Variables finales')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jY3xuy5WY84Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculer le nombre d'investisseurs uniques par startup\n",
        "investor_counts = df_investments_clean.groupby('funded_object_id')['investor_object_id'].nunique().reset_index()\n",
        "investor_counts.columns = ['id', 'investor_count']\n",
        "\n",
        "# Intégrer ce \"Prestige Score\" dans notre dataset final\n",
        "df_final = pd.merge(df_final, investor_counts, on='id', how='left')\n",
        "\n",
        "# Remplacer les NaN par 0 (les startups sans investisseurs listés)\n",
        "df_final['investor_count'] = df_final['investor_count'].fillna(0)\n",
        "\n",
        "print(\"Variable 'investor_count' ajoutée avec succès.\")\n",
        "print(df_final[['name', 'investor_count']].head())"
      ],
      "metadata": {
        "id": "xUn03g7YZ2uP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# 1. Copie de sauvegarde pour la modélisation\n",
        "df_ml = df_final.copy()\n",
        "\n",
        "# 2. Encodage des variables textuelles (Catégories et Pays)\n",
        "le = LabelEncoder()\n",
        "df_ml['category_code'] = le.fit_transform(df_ml['category_code'].astype(str))\n",
        "df_ml['country_code'] = le.fit_transform(df_ml['country_code'].astype(str))\n",
        "\n",
        "# 3. Sélection des features pour le Clustering et le ML\n",
        "# On retire les IDs et les noms qui ne servent pas au calcul\n",
        "features = ['category_code', 'country_code', 'funding_total_usd', 'relationships', 'total_funding_usd', 'investor_count']\n",
        "X = df_ml[features]\n",
        "\n",
        "# 4. Standardisation (Obligatoire pour K-Means)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "MJ6AhDZNacGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Application de K-Means (3 clusters pour la lisibilité)\n",
        "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "df_ml['cluster_profile'] = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Visualisation des profils\n",
        "print(\"Répartition des startups par profil :\")\n",
        "print(df_ml['cluster_profile'].value_counts())\n",
        "\n",
        "# Analyse rapide des groupes\n",
        "cluster_analysis = df_ml.groupby('cluster_profile')[['total_funding_usd', 'investor_count', 'is_success']].mean()\n",
        "print(\"\\nAnalyse moyenne par cluster :\")\n",
        "display(cluster_analysis)"
      ],
      "metadata": {
        "id": "Ushd51DcbKIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# 1. Graphique de la PCA (Visualisation des clusters)\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=df_ml['cluster_profile'], palette='viridis', s=60)\n",
        "plt.title('Visualisation des Clusters (Projection PCA)')\n",
        "plt.xlabel('Composante Principale 1')\n",
        "plt.ylabel('Composante Principale 2')\n",
        "plt.legend(title='Profil')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p2LFOC8Ya421"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_summary = df_ml.groupby('cluster_profile')[['total_funding_usd', 'investor_count', 'relationships']].mean()"
      ],
      "metadata": {
        "id": "cTeYIgW1a_ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_summary_norm = (cluster_summary - cluster_summary.min()) / (cluster_summary.max() - cluster_summary.min())\n",
        "cluster_summary_norm.plot(kind='bar', figsize=(12, 6))\n",
        "plt.title('Comparaison des caractéristiques moyennes par Cluster (Normalisé)')\n",
        "plt.ylabel('Score (0 à 1)')\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DEE6Z9lnbEHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérification de la pertinence des clusters par rapport au succès\n",
        "check_clusters = df_ml.groupby('cluster_profile')['is_success'].mean() * 100\n",
        "print(\"Pourcentage de succès par profil de startup :\")\n",
        "print(check_clusters)"
      ],
      "metadata": {
        "id": "HlFhNjrG_ZNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ÉTAPE : Identification des Licornes Potentielles ---\n",
        "\n",
        "# 1. Filtrer les startups qui n'ont pas encore \"réussi\" (pas encore rachetées/IPO)\n",
        "# On se concentre sur celles qui sont dans le cluster d'élite (Cluster 2)\n",
        "potential_unicorns = df_ml[(df_ml['is_success'] == 0) & (df_ml['cluster_profile'] == 2)].copy()\n",
        "\n",
        "# 2. Création d'un score combiné (Unicorn Score)\n",
        "# On normalise les variables pour qu'elles aient le même poids\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler_score = MinMaxScaler()\n",
        "\n",
        "cols_to_score = ['total_funding_usd', 'investor_count', 'relationships']\n",
        "potential_unicorns['unicorn_score'] = scaler_score.fit_transform(potential_unicorns[cols_to_score]).sum(axis=1)\n",
        "\n",
        "# 3. Sélection du Top 5\n",
        "top_5_unicorns = potential_unicorns.sort_values(by='unicorn_score', ascending=False).head(5)\n",
        "\n",
        "print(\"TOP 5 - Licornes Potentielles (Cibles d'investissement prioritaires) :\")\n",
        "display(top_5_unicorns[['name', 'category_code', 'total_funding_usd', 'investor_count', 'unicorn_score']])\n",
        "\n",
        "# 4. Graphique du Top 5 pour le rapport\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=top_5_unicorns, x='unicorn_score', y='name', color='gold')\n",
        "plt.title('Top 5 des Startups à fort potentiel (Unicorn Status)')\n",
        "plt.xlabel('Score de Potentiel (Finance/Réseau/Relations)')\n",
        "plt.ylabel('Nom de la Startup')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1_2-uXu_NMDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modèle supervisé"
      ],
      "metadata": {
        "id": "oE5OrFB5T88f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# 1. Définition des colonnes (Page 67 du cours)\n",
        "num_features = ['funding_total_usd', 'relationships', 'total_funding_usd', 'investor_count', 'cluster_profile']\n",
        "cat_features = ['category_code', 'country_code']\n",
        "\n",
        "# 2. Preprocessing Pipeline (Bonnes pratiques Module 5)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        # Standarisation par défaut avant de tester d'autres approches (Page 106)\n",
        "        ('num', StandardScaler(), num_features),\n",
        "        # OrdinalEncoder recommandé pour les pipelines (Page 106)\n",
        "        ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), cat_features)\n",
        "    ])\n",
        "\n",
        "# 3. Pipeline complète : Preprocessing + Modèle\n",
        "# scale_pos_weight est utilisé pour gérer le déséquilibre des classes\n",
        "clf = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', XGBClassifier(n_estimators=100, learning_rate=0.1, scale_pos_weight=10, random_state=42))\n",
        "])\n",
        "\n",
        "# 4. Split Train/Test\n",
        "X = df_ml[num_features + cat_features]\n",
        "y = df_ml['is_success']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 5. Entraînement\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# 6. Évaluation (Page 82 du cours)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(f\"Accuracy Score: {accuracy_score(y_test, y_pred):.2%}\")\n",
        "print(\"\\nMatrice de Confusion :\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nRapport de Classification :\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "bcsHWOmBUFrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction de l'importance des variables depuis la pipeline\n",
        "importances = clf.named_steps['classifier'].feature_importances_\n",
        "feature_names = num_features + cat_features\n",
        "\n",
        "# Création du graphique\n",
        "plt.figure(figsize=(10, 6))\n",
        "pd.Series(importances, index=feature_names).sort_values().plot(kind='barh', color='skyblue')\n",
        "plt.title('Quels facteurs prédisent le succès ? (Feature Importance)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r6ZjDKxNVRsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
        "plt.title('Courbe ROC - Performance du Modèle')\n",
        "plt.plot([0, 1], [0, 1], 'k--') # Ligne de base (aléatoire)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Oi11C_p0VmvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import PrecisionRecallDisplay\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "PrecisionRecallDisplay.from_estimator(clf, X_test, y_test)\n",
        "plt.title('Courbe Precision-Recall (Gestion du déséquilibre)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j4TB9lSUVujO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction des noms des colonnes après transformation\n",
        "# Note: On récupère les noms des features définies plus tôt\n",
        "feature_names = num_features + cat_features\n",
        "importances = clf.named_steps['classifier'].feature_importances_\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "feat_importances = pd.Series(importances, index=feature_names)\n",
        "feat_importances.nlargest(10).sort_values().plot(kind='barh', color='teal')\n",
        "plt.title('Top des Facteurs Déterminants du Succès')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XZCSkZS1VxsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# On enregistre la pipeline complète (XGBoost + Preprocessing)\n",
        "joblib.dump(clf, 'models/unicorn_model.pkl')\n",
        "# On enregistre le modèle de clustering\n",
        "joblib.dump(kmeans, 'models/unicorn_clusters.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "wfiMb_9_89tJ",
        "outputId": "8d0f11ef-e16b-44b3-dd09-05dc3d4bb034"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'clf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-816668306.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# On enregistre la pipeline complète (XGBoost + Preprocessing)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models/unicorn_model.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# On enregistre le modèle de clustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models/unicorn_clusters.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
          ]
        }
      ]
    }
  ]
}